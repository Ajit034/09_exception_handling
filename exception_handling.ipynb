{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8b4013b",
   "metadata": {},
   "source": [
    "# 1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
    "\n",
    "Multithreading\n",
    "When to Prefer Multithreading:\n",
    "\n",
    "I/O-Bound Tasks:\n",
    "\n",
    "Multithreading is well-suited for tasks that spend a lot of time waiting for I/O operations to complete (e.g., reading from or writing to files, network communication). This is because threads can perform other operations while waiting for I/O operations to finish, making efficient use of CPU time.\n",
    "\n",
    "Shared Memory Needs:\n",
    "\n",
    "If your tasks need to share data or state frequently and efficiently, multithreading is preferable since threads share the same memory space. This makes it easier to share information between threads compared to processes, which have separate memory spaces.\n",
    "\n",
    "Low Overhead:\n",
    "\n",
    "Threads are generally lighter weight compared to processes. Creating and destroying threads involves less overhead than processes. This makes multithreading more suitable for tasks that require frequent creation and destruction of concurrent tasks.\n",
    "\n",
    "Scenarios Favoring Multithreading:\n",
    "\n",
    "A web server handling multiple requests, where each request involves waiting for I/O operations.\n",
    "An application that requires updating a shared dataset or user interface where multiple threads need to read or write to the same memory space.\n",
    "\n",
    "Multiprocessing\n",
    "When to Prefer Multiprocessing:\n",
    "\n",
    "CPU-Bound Tasks:\n",
    "\n",
    "Multiprocessing is better suited for tasks that require substantial computation and can benefit from running in parallel on multiple CPU cores. Each process has its own Python interpreter and memory space, which helps bypass the Global Interpreter Lock (GIL) in CPython, allowing true parallel execution.\n",
    "Isolation and Fault Tolerance:\n",
    "\n",
    "Processes are completely isolated from each other, so if one process crashes, it does not affect the others. This isolation can improve fault tolerance in applications where tasks might fail independently.\n",
    "\n",
    "Scenarios Favoring Multiprocessing:\n",
    "\n",
    "A data processing pipeline that involves complex computations on large datasets, where different stages of processing can be performed in parallel.\n",
    "A scientific simulation where multiple independent simulations need to be run in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ebd9a",
   "metadata": {},
   "source": [
    "# 2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "What is a process pool?\n",
    "\n",
    "The pool allows you to do multiple jobs per process, which may make it easier to parallelize your program. If you have a million tasks to execute in parallel, you can create a Pool with a number of processes as many as CPU cores and then pass the list of the million tasks to the pool.\n",
    "Key Components of a Process Pool\n",
    "Pool Manager:\n",
    "\n",
    "This component manages the lifecycle of the worker processes, including their creation, termination, and task distribution.\n",
    "Worker Processes:\n",
    "\n",
    "These are the individual processes that perform the actual work. They are kept alive and reused for executing tasks, which avoids the overhead of repeatedly creating and destroying processes.\n",
    "Task Queue:\n",
    "\n",
    "Tasks are typically placed in a queue by the pool manager. The worker processes retrieve tasks from this queue and execute them.\n",
    "\n",
    "How a Process Pool Helps in Managing Multiple Processes Efficiently\n",
    "\n",
    "Reduced Overhead:\n",
    "\n",
    "Creating and destroying processes can be resource-intensive and time-consuming. By maintaining a pool of processes, the overhead associated with process creation and destruction is minimized, leading to better overall performance.\n",
    "Improved Resource Utilization:\n",
    "\n",
    "A process pool helps in optimizing the use of system resources. Instead of having many short-lived processes, which can cause high resource consumption and context switching, a fixed number of worker processes are reused. This leads to more efficient CPU and memory usage.\n",
    "Scalability:\n",
    "\n",
    "By adjusting the number of worker processes in the pool, you can easily scale the processing power according to the workload. This allows the system to handle varying levels of concurrency effectively.\n",
    "Simplified Concurrency Management:\n",
    "\n",
    "Managing a pool of worker processes abstracts away the complexities of handling multiple processes manually. This can simplify the design and implementation of concurrent systems, making it easier to handle task distribution and synchronization.\n",
    "Task Scheduling and Load Balancing:\n",
    "\n",
    "The pool manager can handle scheduling and load balancing of tasks among worker processes. This ensures that tasks are evenly distributed and processed efficiently, avoiding situations where some processes are idle while others are overloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb0968",
   "metadata": {},
   "source": [
    "# 3. Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "Multiprocessing refers to the use of multiple processes to perform multiple tasks at the same time. Each process runs in its own Python interpreter and memory space. Unlike threads, which share the same memory space within a single process, processes in multiprocessing are completely isolated from each other.\n",
    "\n",
    "Why is Multiprocessing Used in Python Programs?\n",
    "Pythonâ€™s multiprocessing is commonly used for several reasons:\n",
    "\n",
    "Bypassing the Global Interpreter Lock (GIL):\n",
    "\n",
    "Python's Global Interpreter Lock (GIL) is a mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes simultaneously. This means that Python threads are not able to fully utilize multiple CPU cores for CPU-bound tasks. Multiprocessing sidesteps this limitation because each process has its own Python interpreter and GIL, allowing true parallelism.\n",
    "Improving Performance in CPU-Bound Tasks:\n",
    "\n",
    "For tasks that require substantial computation (CPU-bound tasks), such as mathematical computations, data processing, or simulations, multiprocessing can significantly improve performance by distributing the workload across multiple CPU cores.\n",
    "Isolated Execution:\n",
    "\n",
    "Each process in a multiprocessing environment runs independently, which means that a failure in one process does not affect others. This isolation can enhance robustness and fault tolerance in applications where tasks might fail independently.\n",
    "Efficient Use of Multi-Core Processors:\n",
    "\n",
    "Modern processors have multiple cores, and multiprocessing enables Python programs to utilize these cores more effectively. By running processes concurrently, programs can handle multiple operations simultaneously, making better use of available hardware.\n",
    "\n",
    "Example:\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(num, queue):\n",
    "    result = num * num\n",
    "    queue.put(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a Queue for inter-process communication\n",
    "    queue = Queue()\n",
    "\n",
    "   \n",
    "    processes = []\n",
    "    for i in range(5):\n",
    "        process = Process(target=worker, args=(i, queue))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "   \n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "   \n",
    "    results = [queue.get() for _ in range(5)]\n",
    "    print(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b543b2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0, List: [0]\n",
      "Removed 0, List: []\n",
      "Added 1, List: [1]\n",
      "Removed 1, List: []\n",
      "Added 2, List: [2]\n",
      "Added 3, List: [2, 3]\n",
      "Removed 2, List: [3]\n",
      "Added 4, List: [3, 4]\n",
      "Added 5, List: [3, 4, 5]\n",
      "Removed 3, List: [4, 5]\n",
      "Added 6, List: [4, 5, 6]\n",
      "Added 7, List: [4, 5, 6, 7]\n",
      "Removed 4, List: [5, 6, 7]\n",
      "Added 8, List: [5, 6, 7, 8]\n",
      "Added 9, List: [5, 6, 7, 8, 9]\n",
      "Removed 5, List: [6, 7, 8, 9]\n",
      "Removed 6, List: [7, 8, 9]\n",
      "Removed 7, List: [8, 9]\n",
      "Removed 8, List: [9]\n",
      "Removed 9, List: []\n",
      "Final List: []\n"
     ]
    }
   ],
   "source": [
    "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
    "# thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
    "# threading.Lock.\n",
    "\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "shared_list = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def add_numbers():\n",
    "    for i in range(10):\n",
    "        with lock:\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i}, List: {shared_list}\")\n",
    "        time.sleep(0.1) \n",
    "\n",
    "def remove_numbers():\n",
    "    for _ in range(10):\n",
    "        with lock:\n",
    "            if shared_list:\n",
    "                removed = shared_list.pop(0)\n",
    "                print(f\"Removed {removed}, List: {shared_list}\")\n",
    "        time.sleep(0.2) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    add_thread = threading.Thread(target=add_numbers)\n",
    "    remove_thread = threading.Thread(target=remove_numbers)\n",
    "    \n",
    "    add_thread.start()\n",
    "    remove_thread.start()\n",
    "    \n",
    "   \n",
    "    add_thread.join()\n",
    "    remove_thread.join()\n",
    "\n",
    "    print(\"Final List:\", shared_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8260d5a",
   "metadata": {},
   "source": [
    "# 5. Describe the methods and tools available in Python for safely sharing data between threads and processes.\n",
    "\n",
    "threading.Lock\n",
    "\n",
    "A Lock object is used to ensure that only one thread can access a critical section of code at a time. The Lock provides a simple way to prevent race conditions by acquiring and releasing the lock around critical sections.\n",
    "\n",
    "example:\n",
    "import threading\n",
    "\n",
    "shared_data = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def thread_function():\n",
    "    global shared_data\n",
    "    with lock:\n",
    "        # Critical section\n",
    "        shared_data.append(1)\n",
    "threading.RLock\n",
    "\n",
    "A RLock (reentrant lock) is similar to Lock, but it allows a thread to acquire the same lock multiple times without causing a deadlock. This is useful in recursive function calls or when a thread needs to acquire the lock more than once.\n",
    "\n",
    "example:\n",
    "\n",
    "import threading\n",
    "\n",
    "shared_data = []\n",
    "rlock = threading.RLock()\n",
    "\n",
    "def thread_function():\n",
    "    global shared_data\n",
    "    with rlock:\n",
    "        # Critical section\n",
    "        shared_data.append(1)\n",
    "        \n",
    "threading.Condition\n",
    "\n",
    "A Condition object is used for more advanced synchronization, allowing threads to wait for some condition to be met before proceeding. It is useful when you need threads to coordinate their actions based on shared state.\n",
    "\n",
    "example:\n",
    "\n",
    "import threading\n",
    "\n",
    "condition = threading.Condition()\n",
    "shared_data = []\n",
    "\n",
    "def producer():\n",
    "    global shared_data\n",
    "    with condition:\n",
    "        shared_data.append(1)\n",
    "        condition.notify()  # Notify waiting threads\n",
    "\n",
    "def consumer():\n",
    "    with condition:\n",
    "        condition.wait()  # Wait for notification\n",
    "        print(shared_data)\n",
    "        \n",
    "Sharing Data Between Processes\n",
    "Processes in Python do not share memory space, so special mechanisms are needed for inter-process communication (IPC). The multiprocessing module provides several tools for safely sharing data between processes:\n",
    "\n",
    "multiprocessing.Queue\n",
    "\n",
    "A Queue is a thread- and process-safe data structure that allows processes to communicate and share data. It supports FIFO (First-In-First-Out) operations and can be used for sending data between processes.\n",
    "\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def worker(queue):\n",
    "    queue.put('Hello from process')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    queue = Queue()\n",
    "    p = Process(target=worker, args=(queue,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(queue.get())\n",
    "    \n",
    "multiprocessing.Pipe\n",
    "\n",
    "A Pipe provides a way to create a two-way communication channel between two processes. It supports sending and receiving data through two endpoints: one for sending data and one for receiving it.\n",
    "\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def worker(conn):\n",
    "    conn.send('Hello from process')\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=worker, args=(child_conn,))\n",
    "    p.start()\n",
    "    p.join()\n",
    "    print(parent_conn.recv())\n",
    "\n",
    "multiprocessing.Manager\n",
    "\n",
    "A Manager provides a way to create and manage shared objects, such as lists, dictionaries, and other data structures, that can be shared between processes. Managers provide proxy objects that synchronize access to the underlying data.\n",
    "\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "def worker(shared_list):\n",
    "    shared_list.append('Hello from process')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Manager() as manager:\n",
    "        shared_list = manager.list()\n",
    "        p = Process(target=worker, args=(shared_list,))\n",
    "        p.start()\n",
    "        p.join()\n",
    "        print(list(shared_list))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b3326",
   "metadata": {},
   "source": [
    "# 6. Discuss why itâ€™s crucial to handle exceptions in concurrent programs and the techniques available for doing so\n",
    "\n",
    "\n",
    "Why Handling Exceptions in Concurrent Programs is Crucial:\n",
    "\n",
    "Unpredictable Behavior:\n",
    "\n",
    "Exceptions in concurrent programs can lead to inconsistent or unpredictable states if not handled properly. For instance, if one thread fails, it might leave shared resources in an inconsistent state.\n",
    "Resource Leaks:\n",
    "\n",
    "Uncaught exceptions can lead to resource leaks, such as file handles, network connections, or memory, which can degrade performance or crash the application.\n",
    "Data Corruption:\n",
    "\n",
    "Concurrent access to shared data can cause data corruption if exceptions are not handled properly. For example, an exception during a write operation might leave the data in an inconsistent state.\n",
    "\n",
    "Techniques for Handling Exceptions in Concurrent Programs\n",
    "\n",
    "Handling Exceptions in Threads\n",
    "Using Try-Except Blocks:\n",
    "\n",
    "Wrap the critical sections of code in try-except blocks within each thread. This allows individual threads to handle exceptions locally.\n",
    "\n",
    "import threading\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        # Code that may raise an exception\n",
    "        raise ValueError(\"An error occurred\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in thread: {e}\")\n",
    "\n",
    "thread = threading.Thread(target=worker)\n",
    "thread.start()\n",
    "thread.join()\n",
    "\n",
    "\n",
    "Exception Handling in Thread Pools:\n",
    "\n",
    "When using thread pools (concurrent.futures.ThreadPoolExecutor), exceptions can be captured through the Future objects returned by submit or map.\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def worker(n):\n",
    "    if n % 2 == 0:\n",
    "        raise ValueError(\"Even number error\")\n",
    "    return n\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(worker, i) for i in range(5)]\n",
    "    for future in futures:\n",
    "        try:\n",
    "            result = future.result()  # This will raise an exception if one occurred\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception from future: {e}\")\n",
    "\n",
    "Handling Exceptions in Processes:\n",
    "\n",
    "Using Try-Except Blocks:\n",
    "\n",
    "Similar to threads, wrap code within processes in try-except blocks to handle exceptions locally within each process.\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "def worker():\n",
    "    try:\n",
    "        # Code that may raise an exception\n",
    "        raise ValueError(\"An error occurred\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in process: {e}\")\n",
    "\n",
    "process = Process(target=worker)\n",
    "process.start()\n",
    "process.join()\n",
    "\n",
    "\n",
    "Exception Handling with Process Pools:\n",
    "\n",
    "When using process pools (multiprocessing.Pool), exceptions can be captured through the results returned by the poolâ€™s methods like map or apply.\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def worker(n):\n",
    "    if n % 2 == 0:\n",
    "        raise ValueError(\"Even number error\")\n",
    "    return n\n",
    "\n",
    "with Pool() as pool:\n",
    "    results = []\n",
    "    for result in pool.imap(worker, range(5)):\n",
    "        try:\n",
    "            print(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception from pool worker: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a120ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 5 is 120\n",
      "Factorial of 4 is 24\n",
      "Factorial of 10 is 3628800\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 6 is 720\n",
      "Factorial of 9 is 362880\n"
     ]
    }
   ],
   "source": [
    "# 7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
    "# Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "# Function to calculate factorial\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    numbers = list(range(1, 11))  # Numbers from 1 to 10\n",
    "    \n",
    "    # Create a ThreadPoolExecutor with a number of workers\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Submit tasks to the executor\n",
    "        futures = {executor.submit(factorial, num): num for num in numbers}\n",
    "        \n",
    "        # Collect results as they are completed\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            num = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f\"Factorial of {num} is {result}\")\n",
    "            except Exception as exc:\n",
    "                print(f\"An exception occurred for {num}: {exc}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c33c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
    "# parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
    "# processes).\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "\n",
    "def compute_squares(pool_size):\n",
    "    with multiprocessing.Pool(processes=pool_size) as pool:\n",
    "        \n",
    "        numbers = list(range(1, 11))\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = pool.map(square, numbers)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        duration = end_time - start_time\n",
    "        return results, duration\n",
    "\n",
    "# Main function to test different pool sizes\n",
    "def main():\n",
    "    pool_sizes = [2, 4, 8]\n",
    "    \n",
    "    for pool_size in pool_sizes:\n",
    "        results, duration = compute_squares(pool_size)\n",
    "        print(f\"Pool size: {pool_size}\")\n",
    "        print(f\"Results: {results}\")\n",
    "        print(f\"Time taken: {duration:.4f} seconds\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a324b6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
